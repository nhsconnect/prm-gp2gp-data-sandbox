{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRMT-1181 Attachment Metadata Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "PCSE want to be able to understand the scope and size of the GP2GP fallback service. They want to know more about the types of attachments that come via GP2GP.\n",
    "\n",
    "They would like to know:\n",
    "- Average and maximum file sizes\n",
    "- Graph which demonstrates distribution of file sizes\n",
    "- Identify File types that got as far as the transfer\n",
    "- Add graph on number of attachments\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "#### Each row of the attachments data set represents a unique attachment.\n",
    "\n",
    "The core assumption made in this analysis is that each row is a different attachment. However, attachment ids do not uniquely idefity a each row of data within the same GP2GP transfer, despite sizes and types of attachments nevertheless varying. See appendix 1 for an example.\n",
    "\n",
    "#### Attachments appear in the attachments dataset shortly after the transfer is requested.\n",
    "\n",
    "This needs to be the case if we are to calculate how many gp2gp tranfers have no attachments.\n",
    "\n",
    "This appears to be true (within two hours) for 99% of our data. See appendix 2 for more.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "In order to replicate this notebook, perform the following steps:\n",
    "\n",
    "1. Log into Splunk and run the following query, for 21/12/2020 00:00:00:00 to 27/12/2020 24:00:00 and 28/12/2020 00:00:00:00 to 03/01/2020 24:00:00 time frames (currently there are issues with downloading large data sets in Splunk):\n",
    "\n",
    "```\n",
    "index=\"spine2vfmmonitor\" logReference=MPS0208\n",
    "| fields _time, attachmentID, conversationID, FromSystem, ToSystem, attachmentType, Compressed, ContentType, LargeAttachment, Length, OriginalBase64\n",
    "| fields - _raw\n",
    "```\n",
    "\n",
    "2. Download the two data sets as CSVs and place in a directory called `attachments_metadata`. Set the `INPUT_DATA_DIR` environment variable to point to the _parent_ of this directory.\n",
    "\n",
    "3. Run the following Splunk query for the same time range, and place the CSV in a directory alongside the first one called `gp2gp_requests`.\n",
    "\n",
    "```\n",
    "index=\"spine2vfmmonitor\" service=\"gp2gp\" interactionID=\"urn:nhs:names:services:gp2gp/RCMR_IN010000UK05\"\n",
    "| fields _time, conversationID\n",
    "| fields - _raw\n",
    "```\n",
    "\n",
    "Example directory layout, where `INPUT_DATA_DIR` is `/attachments`.\n",
    "```\n",
    "/attachments/attachments_metadata/attachments_one.csv\n",
    "/attachments/attachments_metadata/attachments_two.csv\n",
    "/attachments/gp2gp_requests/requests.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths, os\n",
    "import duckdb\n",
    "from scripts.attachments import construct_attachments_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_data_dir = os.environ[\"INPUT_DATA_DIR\"]\n",
    "cursor =  duckdb.connect()\n",
    "construct_attachments_db(cursor, attachment_data_dir)\n",
    "attachments = cursor.table(\"attachment_metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attachment types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(start_time, end_time) = attachments\\\n",
    "    .aggregate(\"MIN(time) as start_time, MAX(time) as end_time\") \\\n",
    "    .execute().fetchone()\n",
    "\n",
    "start_date = start_time.date()\n",
    "end_date = end_time.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_count = attachments.aggregate(\"COUNT(*)\").df()\n",
    "print(f\"{attachment_count.iat[0, 0]} attachments in dataset ({start_date} to {end_date})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of attachments by file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_per_content_type = attachments.aggregate(\"content_type, count(*) as count\").order(\"count DESC\").df()\n",
    "attachment_type_bars = attachments_per_content_type.plot.bar(\n",
    "    x=\"content_type\", y=\"count\",\n",
    "    title=f\"Count of attachments by file type, {start_date} to {end_date}\",\n",
    "    rot=45,\n",
    "    figsize=(16,8),\n",
    "    legend=False,\n",
    ")\n",
    "attachment_type_bars.set(xlabel=\"Attachment file type\", ylabel=\"Number of attachments\")\n",
    "attachment_type_bars.ticklabel_format(style='plain', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_per_content_type.set_index(\"content_type\").style.set_caption(f\"Count of attachments by file type, {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of transfers with attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_count, with_attachment_count, without_attachment_count = cursor.execute(\"\"\"\n",
    "    select\n",
    "        count(*) as transfers,\n",
    "        sum(case when attachments.conversation_id is not null then 1 else 0 end) as with_attachments,\n",
    "        sum(case when attachments.conversation_id is null then 1 else 0 end) as without_attachments\n",
    "    from gp2gp_requests\n",
    "    left join (select distinct conversation_id from attachment_metadata) attachments\n",
    "    on attachments.conversation_id=gp2gp_requests.conversation_id\n",
    "\"\"\").fetchone()\n",
    "percent_with_attachment = with_attachment_count/transfer_count*100\n",
    "print(f\"Out of {transfer_count} transfers made between {start_date} and {end_date}, {with_attachment_count} had at least one attachment. ({percent_with_attachment}%) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of attachments per transfer (excluding transfers with no attachments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_per_transfer = attachments.aggregate(\"conversation_id, count(*) as count\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_per_transfer_truncated = attachments.aggregate(\"conversation_id, count(*) as count\").filter(\"count <= 1000\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_per_transfer_hist_truncated = attachments_per_transfer_truncated.plot.hist(\n",
    "    title=f\"Histogram of attachments per transfer (where transfer has less than 1000 attachments), {start_date} to {end_date}\",\n",
    "    legend=False,\n",
    "    bins=150, figsize=(14,8)\n",
    ")\n",
    "attachments_per_transfer_hist = attachments_per_transfer.plot.hist(\n",
    "    title=f\"Histogram of attachments per transfer, {start_date} to {end_date}\",\n",
    "    legend=False,\n",
    "    bins=150, figsize=(14,8)\n",
    ")\n",
    "attachments_per_transfer_hist_truncated.set(xlabel=\"Attachments per transfer\", ylabel=\"Frequency\")\n",
    "attachments_per_transfer_hist_truncated.ticklabel_format(style='plain', axis='y')\n",
    "attachments_per_transfer_hist.set(xlabel=\"Attachments per transfer\", ylabel=\"Frequency\")\n",
    "attachments_per_transfer_hist.ticklabel_format(style='plain', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_per_transfer.describe().style.set_caption(f\"Count of attachments per transfer, {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_lengths = attachments.project(\"content_type, length/(1024.0*1024.0) as megabytes\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_lengths.describe().style.set_caption(f\"Attachment file sizes (bytes), {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_lengths_hist = attachment_lengths.plot.hist(\n",
    "    title=f\"Histogram of attachment size (logarithmic), {start_date} to {end_date}\",\n",
    "    legend=False,\n",
    "    bins=100, log=True, figsize=(14,8)\n",
    ")\n",
    "attachment_lengths_hist.set(xlabel=\"Attachment size (MB)\", ylabel=\"Frequency (logarithmic)\")\n",
    "attachment_lengths_hist.ticklabel_format(style='plain', axis='x', useOffset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_lengths_hist_lin = attachment_lengths.plot.hist(\n",
    "    title=f\"Histogram of attachment size (linear), {start_date} to {end_date}\",\n",
    "    legend=False,\n",
    "    bins=100, log=False, figsize=(14,8)\n",
    ")\n",
    "attachment_lengths_hist_lin.set(xlabel=\"Attachment size (MB)\", ylabel=\"Frequency (linear)\")\n",
    "attachment_lengths_hist_lin.ticklabel_format(style='plain', axis='y', useOffset=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attachment size by file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_lengths.groupby('content_type').describe().style.set_caption(\"Attachment file sizes by content type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_lengths_boxplot = attachment_lengths.boxplot(\n",
    "    'megabytes', by='content_type',\n",
    "    figsize=(14,8),\n",
    "    showfliers=False,\n",
    "    rot=45,\n",
    ")\n",
    "attachment_lengths_boxplot.set_title(f\"Boxplot of attachment size by content type (outliers removed), {start_date} to {end_date}\")\n",
    "attachment_lengths_boxplot.set(xlabel=\"Attachment type\", ylabel=\"Size (MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: Attachment uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments.aggregate(\"count(*)\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"select count(*) from (select distinct conversation_id, attachment_id from attachment_metadata) uniq\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"select count(*) from (select distinct conversation_id from attachment_metadata) uniq\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converstaion_attachment_counts = attachments\\\n",
    "    .aggregate(\"conversation_id, count(*) as rows, count(distinct(attachment_id)) as unique_attachments\")\\\n",
    "    .create_view(\"convo_attachment_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converstaion_attachment_counts.filter(\"rows != unique_attachments\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Combinding attachment logs and main spine logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp2gp_attachments = cursor.execute(\"\"\"\n",
    "    select\n",
    "        count(*) as row_count,\n",
    "        sum(case when gp2gp_requests.conversation_id is null then 1 else 0 end) as attachments_with_no_transfer,\n",
    "        sum(case when attachments.conversation_id is null then 1 else 0 end) as transfers_with_no_attachments\n",
    "    from (select distinct conversation_id from attachment_metadata) attachments\n",
    "    full outer join gp2gp_requests\n",
    "    on attachments.conversation_id=gp2gp_requests.conversation_id\n",
    "\"\"\").df()\n",
    "gp2gp_attachments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp2gp_requests = cursor.execute(\"\"\"\n",
    "    select gp2gp_requests.time as req_time, attach.time as attach_time\n",
    "    FROM gp2gp_requests\n",
    "    LEFT JOIN (select conversation_id, max(time) as time from attachment_metadata group by conversation_id) attach\n",
    "    ON attach.conversation_id=gp2gp_requests.conversation_id\n",
    "\"\"\").df()\n",
    "\n",
    "gp2gp_requests[\"time_delta\"] = gp2gp_requests[\"attach_time\"] - gp2gp_requests[\"req_time\"]\n",
    "gp2gp_requests[\"time_delta_sec\"]= gp2gp_requests[\"time_delta\"].astype('timedelta64[s]')\n",
    "gp2gp_requests[\"time_delta_sec\"].describe(percentiles=[.25, .50, .75, .90, .99]).apply(lambda x: format(x, '.1f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
