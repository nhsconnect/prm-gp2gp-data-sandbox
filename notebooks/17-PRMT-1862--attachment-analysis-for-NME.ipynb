{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hearing-spain",
   "metadata": {},
   "source": [
    "# PRMT-1862 Attachment Size Analysis for NME (New Market Entrant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-leadership",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "The NME/GPC team need to understand the size of the attachments being transferred via GP2GP, in order to inform their decisions for GP Connect and reduce the need to chunk attachments. They would like to know:\n",
    "- The max file size that can be transferred without the request timing out.\n",
    "\n",
    "There is some effort required to de-duplicate the underlying data. This is explored in notebook `10-PRMT-1528` and `PRMT-1724`. The date range used was 1st January 2021 00:00:00 to 31 March 2021 24:00:00.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "In order to replicate this notebook, perform the following steps:\n",
    "\n",
    "1. Log into Splunk and run the following query for:\n",
    "- 01/01/2021 00:00:00:00 to 17/01/2021 24:00:00 (using Date Range) and export the result as a CSV named `1-jan-17-jan-2021-attachment-data`\n",
    "- 18/01/2021 00:00:00:00 to 31/01/2021 24:00:00 (using Date Range) and export the result as a CSV named `18-jan-31-jan-2021-attachment-data`\n",
    "- 01/02/2021 00:00:00:00 to 14/02/2021 24:00:00 (using Date Range) and export the result as a CSV named `01-feb-14-feb-2021-attachment-data`\n",
    "- 15/02/2021 00:00:00:00 to 28/02/2021 24:00:00 (using Date Range) and export the result as a CSV named `15-feb-28-feb-2021-attachment-data`\n",
    "- 01/03/2021 00:00:00:00 to 14/03/2021 24:00:00 (using Date Range) and export the result as a CSV named `1-mar-14-mar-2021-attachment-data.`\n",
    "- 15/03/2021 00:00:00:00 to 21/03/2021 24:00:00 (using Date Range) and export the result as a CSV named `15-mar-21-mar-2021-attachment-data`\n",
    "- 22/03/2021 00:00:00:00 to 31/03/2021 24:00:00 (using Date Range) and export the result as a CSV named `22-mar-31-mar-2021-attachment-data`\n",
    "\n",
    "\n",
    "Splunk Query for all attachment metadata:\n",
    "```\n",
    "index=\"spine2vfmmonitor\" logReference=MPS0208\n",
    "| table  *\n",
    "```\n",
    "\n",
    "2. Run the following Splunk query for the following month ranges:\n",
    "- 01/01/2021 00:00:00:00 to 31/01/2021 24:00:00 (using Date Range) and export result as `1-2021-gp2gp-messages.csv`\n",
    "- 01/02/2021 00:00:00:00 to 28/02/2021 24:00:00 (using Date Range) and expoert result as `2-2021-gp2gp-messages.csv`\n",
    "- 01/03/2021 00:00:00:00 to 31/03/2021 24:00:00 (using Date Range) and export result as `3-2021-gp2gp-messages.csv`\n",
    "\n",
    "Splunk query for GP2GP messages:\n",
    "```\n",
    "index=\"spine2vfmmonitor\" service=\"gp2gp\" logReference=\"MPS0053c\"\n",
    "| table _time, conversationID, internalID, interactionID\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "absent-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lesbian-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_metadata_prefix = \"s3://prm-gp2gp-data-sandbox-dev/attachment-insights/attachments-metadata--all-fields/\"\n",
    "attachment_files = [\n",
    "    \"1-jan-17-jan-2021-attachment-data.csv.gz\",\n",
    "    \"18-jan-31-jan-2021-attachment-data.csv.gz\",\n",
    "    \"1-feb-14-feb-2021-attachment-data.csv.gz\",\n",
    "    \"15-feb-28-feb-2021-attachment-data.csv.gz\",\n",
    "    \"1-mar-14-mar-2021-attachment-data.csv.gz\",\n",
    "    \"15-mar-21-mar-2021-attachment-data.csv.gz\",\n",
    "    \"22-mar-31-mar-2021-attachment-data.csv.gz\"\n",
    "]\n",
    "attachment_input_files = [attachments_metadata_prefix + f for f in attachment_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(val):\n",
    "    if val == \"Unknown\":\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return np.int(val)\n",
    "\n",
    "attachments = pd.concat((\n",
    "    pd.read_csv(f, converters={\"Length\": convert_to_int}, parse_dates=[\"_time\"])\n",
    "    for f in attachment_input_files\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp2gp_messages_prefix = \"s3://prm-gp2gp-data-sandbox-dev/attachment-insights/gp2gp-messages/\"\n",
    "gp2gp_messages_files = [\n",
    "    \"1-2021-gp2gp-messages.csv.gz\",\n",
    "    \"2-2021-gp2gp-messages.csv.gz\",\n",
    "    \"3-2021-gp2gp-messages.csv.gz\"\n",
    "]\n",
    "gp2gp_messages_input_files = [gp2gp_messages_prefix + f for f in gp2gp_messages_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp2gp_messages = pd.concat((\n",
    "    pd.read_csv(f, parse_dates=[\"_time\"])\n",
    "    for f in gp2gp_messages_input_files\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-printer",
   "metadata": {},
   "source": [
    "## Deduplicate Attachment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_request_completed_messages = gp2gp_messages[gp2gp_messages[\"interactionID\"] == \"urn:nhs:names:services:gp2gp/RCMR_IN030000UK06\"]\n",
    "\n",
    "unique_ehr_request_completed_messages = ehr_request_completed_messages.sort_values(by=\"_time\").drop_duplicates(subset=[\"conversationID\"], keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_attachments = pd.merge(attachments, unique_ehr_request_completed_messages[[\"internalID\", \"interactionID\"]], on=\"internalID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-boxing",
   "metadata": {},
   "source": [
    "## Attachment sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_attachments_with_size_in_mb = ehr_attachments.assign(LengthInMB=lambda x: x[\"Length\"]/ (1024 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_over_5_mb = np.sum((ehr_attachments_with_size_in_mb[\"LengthInMB\"] >= 5) & (ehr_attachments_with_size_in_mb[\"LengthInMB\"] < 20))\n",
    "attachments_over_20_mb = np.sum(ehr_attachments_with_size_in_mb[\"LengthInMB\"] >= 20)\n",
    "attachments_under_5_mb = np.sum(ehr_attachments_with_size_in_mb[\"LengthInMB\"] < 5)\n",
    "attachments_size_unknown = np.sum(ehr_attachments_with_size_in_mb[\"LengthInMB\"].isnull())\n",
    "\n",
    "attachment_sizes = pd.DataFrame([[attachments_over_5_mb, attachments_over_20_mb, attachments_under_5_mb, attachments_size_unknown]],\n",
    "                  columns=['over 5 MB', 'over 20 MB', 'under 5 MB', 'Unknown'])\n",
    "attachment_sizes['Total'] = attachment_sizes.sum(axis=1)\n",
    "attachment_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment_size_percentages = attachment_sizes.iloc[:, 0:4].apply(lambda x: x / attachment_sizes.iloc[:, 4] * 100)\n",
    "\n",
    "attachment_size_percentages = attachment_size_percentages.add_suffix(' (%)')\n",
    "\n",
    "attachment_size_percentages.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
