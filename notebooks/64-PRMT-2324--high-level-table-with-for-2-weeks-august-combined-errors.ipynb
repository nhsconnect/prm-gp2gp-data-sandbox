{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d7c794",
   "metadata": {},
   "source": [
    "# PRMT-2324 Run top level table for first 2 weeks of August 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae221d",
   "metadata": {},
   "source": [
    "## Context\n",
    "In our July data we saw a significant increase in GP2GP failures. We want to understand if these were blips, perhaps caused by something that happening during July, or whether these failures are continuing. We donâ€™t want to wait until we have all August data to identify this as we are starting conversations with suppliers now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57474243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1bf068",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_file_location = \"s3://prm-gp2gp-notebook-data-prod/PRMT-2324-2-weeks-august-data/transfers/v4/2021/8/transfers.parquet\"\n",
    "\n",
    "transfers_raw = pd.read_parquet(transfer_file_location)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220ba251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data to just include the first 2 weeks of august\n",
    "date_filter_bool = transfers_raw[\"date_requested\"] < datetime(2021, 8, 16)\n",
    "transfers_half_august = transfers_raw[date_filter_bool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6418953",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = transfers_half_august.copy()\n",
    "transfers[\"status\"] = transfers[\"status\"].str.replace(\"_\", \" \").str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe6dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths, data\n",
    "error_code_lookup_file = pd.read_csv(data.gp2gp_response_codes.path)\n",
    "error_code_lookup = error_code_lookup_file.set_index(\"ErrorCode\")[\"ErrorName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d844356e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unexpected EHR'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_code_lookup[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ffb1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_error_list_to_tuple(error_code_list, error_code_type):\n",
    "    return [(error_code_type, error_code, error_code_lookup[error_code]) for error_code in set(error_code_list) if not np.isnan(error_code)]\n",
    "\n",
    "def combine_error_codes(row):\n",
    "    sender_list = convert_error_list_to_tuple(row[\"sender_error_codes\"], \"Sender\")\n",
    "    intermediate_list = convert_error_list_to_tuple(row[\"intermediate_error_codes\"], \"COPC\")\n",
    "    final_list = convert_error_list_to_tuple(row[\"final_error_codes\"], \"Final\")\n",
    "    full_error_code_list = sender_list + intermediate_list + final_list\n",
    "    if len(full_error_code_list) == 0:\n",
    "        return tuple([(\"No Error Code\", \"No Error\", \"N/A\")])\n",
    "    else:\n",
    "        return tuple(full_error_code_list)\n",
    "    \n",
    "transfers[\"all_error_codes\"] = transfers.apply(combine_error_codes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1970c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "609172bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarized_error_codes(table_sample):\n",
    "# keeping this in case we want to consolidate error codes based ont he int value rather then combined with error code type\n",
    "    table_sample[\"error_code_list\"]=table_sample[\"all_error_codes\"].apply(lambda error_tuple_list: [error_tuple[1] for error_tuple in error_tuple_list if type(error_tuple[1])!=str])\n",
    "\n",
    "    # split out error codes so we can use them to filter\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binarized = mlb.fit_transform(table_sample[\"error_code_list\"])\n",
    "    binarized_error_occurences = pd.DataFrame(data=binarized, columns=mlb.classes_, index=table_sample.index)\n",
    "\n",
    "    return pd.concat([table_sample, binarized_error_occurences], axis=1).drop('error_code_list',axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03723300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_high_level_table(transfers_sample):\n",
    "\n",
    "    # Create High level table\n",
    "    high_level_table=transfers_sample.fillna(\"N/A\").groupby([\"requesting_supplier\",\"sending_supplier\",\"status\",\"failure_reason\",\"all_error_codes\"]).agg({\"conversation_id\":\"count\"})\n",
    "    high_level_table=high_level_table.rename({\"conversation_id\":\"Number of Transfers\"},axis=1).reset_index()\n",
    "\n",
    "    # Count % of transfers\n",
    "    total_number_transfers = transfers_sample.shape[0]\n",
    "    high_level_table[\"% of Transfers\"]=(high_level_table[\"Number of Transfers\"]/total_number_transfers).multiply(100)\n",
    "\n",
    "    # Count by supplier pathway\n",
    "    supplier_pathway_counts = transfers_sample.fillna(\"Unknown\").groupby(by=[\"sending_supplier\", \"requesting_supplier\"]).agg({\"conversation_id\": \"count\"})[\"conversation_id\"]\n",
    "    high_level_table[\"% Supplier Pathway Transfers\"]=high_level_table.apply(lambda row: row[\"Number of Transfers\"]/supplier_pathway_counts.loc[(row[\"sending_supplier\"],row[\"requesting_supplier\"])],axis=1).multiply(100)\n",
    "\n",
    "    # Add in Paper Fallback columns\n",
    "    total_fallback = transfers_sample[\"failure_reason\"].dropna().shape[0]\n",
    "    fallback_bool=high_level_table[\"status\"]!=\"Integrated On Time\"\n",
    "    high_level_table.loc[fallback_bool,\"% Paper Fallback\"]=(high_level_table[\"Number of Transfers\"]/total_fallback).multiply(100)\n",
    "\n",
    "    # % of error codes column\n",
    "    no_error_tuple = tuple([(\"No Error Code\", \"No Error\", \"N/A\")])\n",
    "    error_code_bool = transfers_sample[\"all_error_codes\"]!=no_error_tuple\n",
    "    total_number_of_error_code_combinations=error_code_bool.sum()\n",
    "    table_error_code_bool = high_level_table[\"all_error_codes\"]!=no_error_tuple\n",
    "    high_level_table.loc[table_error_code_bool,\"% of error codes\"]=(high_level_table.loc[table_error_code_bool, \"Number of Transfers\"]/total_number_of_error_code_combinations).multiply(100)\n",
    "    \n",
    "    # Select and re-order table\n",
    "    grouping_columns_order=[\"requesting_supplier\",\"sending_supplier\",\"status\",\"failure_reason\", \"all_error_codes\"]\n",
    "    counting_columns_order=[\"Number of Transfers\",\"% of Transfers\",\"% Supplier Pathway Transfers\",\"% Paper Fallback\",\"% of error codes\"]\n",
    "    high_level_table=high_level_table[grouping_columns_order+counting_columns_order].sort_values(by=\"Number of Transfers\",ascending=False)\n",
    "    \n",
    "    high_level_table=binarized_error_codes(high_level_table)\n",
    "    return high_level_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b76e29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers['month']=transfers['date_requested'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0974efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"Error Code Combinations Tables First 2 Weeks of August PRMT-2324.xlsx\") as writer:\n",
    "    generate_high_level_table(transfers.copy()).to_excel(writer, sheet_name=\"All\",index=False)\n",
    "    [generate_high_level_table(transfers[transfers['month']==month].copy()).to_excel(writer, sheet_name=str(month),index=False) for month in transfers['month'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff828dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30acf9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7769202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
